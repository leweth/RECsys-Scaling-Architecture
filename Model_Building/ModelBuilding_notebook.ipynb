{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Le bloc de code suivant est utilisé pour l'installation d'Apache Spark, prit de ce notebook:\n",
        "https://colab.research.google.com/github/groda/big_data/blob/master/Run_Spark_on_Google_Colab.ipynb"
      ],
      "metadata": {
        "id": "q5Nn8FqWzj-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import subprocess\n",
        "import os\n",
        "import re\n",
        "import socket\n",
        "import shutil\n",
        "import time\n",
        "import sys\n",
        "\n",
        "def run(cmd):\n",
        "    # run a shell command\n",
        "    try:\n",
        "        # Run the command and capture stdout and stderr\n",
        "        subprocess_output = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        # Access stdout (stderr redirected to stdout)\n",
        "        stdout_result = subprocess_output.stdout.strip().splitlines()[-1]\n",
        "        # Process the results as needed\n",
        "        print(f'✅ {stdout_result}')\n",
        "        return stdout_result\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # Handle the error if the command returns a non-zero exit code\n",
        "        print(f\"Command failed with return code {e.returncode}\")\n",
        "        print(\"stdout:\", e.stdout)\n",
        "\n",
        "def is_java_installed():\n",
        "    return shutil.which(\"java\")\n",
        "\n",
        "def install_java():\n",
        "    # Uncomment and modify the desired version\n",
        "    # java_version= 'openjdk-11-jre-headless'\n",
        "    # java_version= 'default-jre'\n",
        "    # java_version= 'openjdk-17-jre-headless'\n",
        "    # java_version= 'openjdk-18-jre-headless'\n",
        "    java_version= 'openjdk-19-jre-headless'\n",
        "    os.environ['JAVA_HOME'] = ' /usr/lib/jvm/java-19-openjdk-amd64'\n",
        "    print(f\"Java not found. Installing {java_version} ... (this might take a while)\")\n",
        "    try:\n",
        "        cmd = f\"apt install -y {java_version}\"\n",
        "        subprocess_output = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        stdout_result = subprocess_output.stdout\n",
        "        # Process the results as needed\n",
        "        print(f'✅ Done installing Java {java_version}')\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # Handle the error if the command returns a non-zero exit code\n",
        "        print(f\"Command failed with return code {e.returncode}\")\n",
        "        print(\"stdout:\", e.stdout)\n",
        "\n",
        "print(\"\\n0️⃣   Install Java if not available\")\n",
        "if is_java_installed():\n",
        "    print(\"✅ Java is already installed.\")\n",
        "else:\n",
        "    install_java()\n",
        "\n",
        "print(\"\\n1️⃣   Download and install Hadoop and Spark\")\n",
        "# URL for downloading Hadoop and Spark\n",
        "SPARK_VERSION = \"3.5.1\"\n",
        "HADOOP_SPARK_URL = \"https://dlcdn.apache.org/spark/spark-\" + SPARK_VERSION + \\\n",
        "                   \"/spark-\" + SPARK_VERSION + \"-bin-hadoop3.tgz\"\n",
        "r = requests.head(HADOOP_SPARK_URL)\n",
        "if r.status_code >= 200 and r.status_code < 400:\n",
        "    print(f'✅ {HADOOP_SPARK_URL} was found')\n",
        "else:\n",
        "    SPARK_CDN = \"https://dlcdn.apache.org/spark/\"\n",
        "    print(f'⚠️ {HADOOP_SPARK_URL} was NOT found. \\nCheck for available Spark versions in {SPARK_CDN}')\n",
        "\n",
        "# set some environment variables\n",
        "os.environ['SPARK_HOME'] = os.path.join(os.getcwd(), os.path.splitext(os.path.basename(HADOOP_SPARK_URL))[0])\n",
        "os.environ['PATH'] = ':'.join([os.path.join(os.environ['SPARK_HOME'], 'bin'), os.environ['PATH']])\n",
        "os.environ['PATH'] = ':'.join([os.path.join(os.environ['SPARK_HOME'], 'sbin'), os.environ['PATH']])\n",
        "\n",
        "# download Spark\n",
        "# using --no-clobber option will prevent wget from downloading file if already present\n",
        "# shell command: wget --no-clobber $HADOOP_SPARK_URL\n",
        "cmd = f\"wget --no-clobber {HADOOP_SPARK_URL}\"\n",
        "run(cmd)\n",
        "\n",
        "# uncompress\n",
        "try:\n",
        "    # Run the command and capture stdout and stderr\n",
        "    cmd = \"([ -d $(basename {0}|sed 's/\\.[^.]*$//') ] && echo -n 'Folder already exists') || (tar xzf $(basename {0}) && echo 'Uncompressed Spark distribution')\"\n",
        "    subprocess_output = subprocess.run(cmd.format(HADOOP_SPARK_URL), shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    # Access stdout (stderr redirected to stdout)\n",
        "    stdout_result = subprocess_output.stdout\n",
        "    # Process the results as needed\n",
        "    print(f'✅ {stdout_result}')\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    # Handle the error if the command returns a non-zero exit code\n",
        "    print(f\"Command failed with return code {e.returncode}\")\n",
        "    print(\"stdout:\", e.stdout)\n",
        "\n",
        "\n",
        "print(\"\\n2️⃣   Start Spark engine\")\n",
        "# start master\n",
        "# shell command: $SPARK_HOME/sbin/start-master.sh\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'stop-master.sh')\n",
        "run(cmd)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'start-master.sh')\n",
        "out = run(cmd)\n",
        "\n",
        "# start one worker (first stop it in case it's already running)\n",
        "# shell command: $SPARK_HOME/sbin/start-worker.sh spark://${HOSTNAME}:7077\n",
        "cmd = [os.path.join(os.environ['SPARK_HOME'], 'sbin', 'stop-worker.sh')]\n",
        "run(cmd)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'start-worker.sh') + ' ' + 'spark://'+socket.gethostname()+':7077'\n",
        "run(cmd)\n",
        "\n",
        "print(\"\\n3️⃣   Start Master Web UI\")\n",
        "# get master UI's port number\n",
        "# the subprocess that's starting the master with start-master.sh\n",
        "# might still not be ready with assigning the port number at this point\n",
        "# therefore we check the logfile a few times (attempts=5) to see if the port\n",
        "# has been assigned. This might take 1-2 seconds.\n",
        "\n",
        "master_log = out.partition(\"logging to\")[2].strip()\n",
        "print(\"Search for port number in log file {}\".format(master_log))\n",
        "attempts = 10\n",
        "search_pattern = \"Successfully started service 'MasterUI' on port (\\d+)\"\n",
        "found = False\n",
        "for i in range(attempts):\n",
        "  if not found:\n",
        "   with open(master_log) as log:\n",
        "      found = re.search(search_pattern, log.read())\n",
        "      if found:\n",
        "          webUIport = found.group(1)\n",
        "          print(f\"✅ Master UI is available at localhost:{webUIport} (attempt nr. {i})\")\n",
        "          break\n",
        "      else:\n",
        "          time.sleep(2) # need to try until port information is found in the logfile\n",
        "          i+=1\n",
        "if not found:\n",
        "  print(\"Could not find port for Master Web UI\\n\")\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    # serve the Web UI on Colab\n",
        "    print(\"Click on the link below to open the Spark Web UI 🚀\")\n",
        "    from google.colab import output\n",
        "    output.serve_kernel_port_as_window(webUIport)\n",
        "\n",
        "print(\"\\n4️⃣   Start history server\")\n",
        "# start history server\n",
        "# shell command: mkdir -p /tmp/spark-events\n",
        "# shell command: $SPARK_HOME/sbin/start-history-server.sh\n",
        "spark_events_dir = os.path.join('/tmp', 'spark-events')\n",
        "if not os.path.exists(spark_events_dir):\n",
        "    os.mkdir(spark_events_dir)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'stop-history-server.sh')\n",
        "run(cmd)\n",
        "cmd = os.path.join(os.environ['SPARK_HOME'], 'sbin', 'start-history-server.sh')\n",
        "run(cmd)\n",
        "\n",
        "if IN_COLAB:\n",
        "    # serve the History Server\n",
        "    print(\"Click on the link below to open the Spark History Server Web UI 🚀\")\n",
        "    output.serve_kernel_port_as_window(18080)\n"
      ],
      "metadata": {
        "id": "j0ya6VMzXbKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "b1e32570-3a0a-4d9f-8a45-6e4434902b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0️⃣   Install Java if not available\n",
            "✅ Java is already installed.\n",
            "\n",
            "1️⃣   Download and install Hadoop and Spark\n",
            "✅ https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz was found\n",
            "✅ File ‘spark-3.5.1-bin-hadoop3.tgz’ already there; not retrieving.\n",
            "✅ Folder already exists\n",
            "\n",
            "2️⃣   Start Spark engine\n",
            "✅ stopping org.apache.spark.deploy.master.Master\n",
            "✅ starting org.apache.spark.deploy.master.Master, logging to /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.master.Master-1-05f026f3848f.out\n",
            "✅ stopping org.apache.spark.deploy.worker.Worker\n",
            "✅ starting org.apache.spark.deploy.worker.Worker, logging to /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.worker.Worker-1-05f026f3848f.out\n",
            "\n",
            "3️⃣   Start Master Web UI\n",
            "Search for port number in log file /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.master.Master-1-05f026f3848f.out\n",
            "✅ Master UI is available at localhost:8081 (attempt nr. 2)\n",
            "Click on the link below to open the Spark Web UI 🚀\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8081, \"/\", \"https://localhost:8081/\", window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4️⃣   Start history server\n",
            "✅ stopping org.apache.spark.deploy.history.HistoryServer\n",
            "✅ starting org.apache.spark.deploy.history.HistoryServer, logging to /content/spark-3.5.1-bin-hadoop3/logs/spark--org.apache.spark.deploy.history.HistoryServer-1-05f026f3848f.out\n",
            "Click on the link below to open the Spark History Server Web UI 🚀\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(18080, \"/\", \"https://localhost:18080/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation de PySpark, l'API Python pour Spark"
      ],
      "metadata": {
        "id": "96jI8C2uzzxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "xeM78PUorCke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32eeeeae-d9b9-4041-d4c0-cca2b17af4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importation de tous les packages nécessaires"
      ],
      "metadata": {
        "id": "OvlMeoQ1z7Uq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHK2xNLLn5zf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "import random\n",
        "import json\n",
        "import gzip\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connexion à la session Google Drive"
      ],
      "metadata": {
        "id": "uQYDtuz30Avk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vQJWapzXq5ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ca7cf4-8411-4cce-b4ae-8125affe21c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Démarrage de la session PySpark"
      ],
      "metadata": {
        "id": "Q8cG6XfS0GFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "CqtM6co_rJvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spécification du chemin pour le jeu de données"
      ],
      "metadata": {
        "id": "g6rN15nh0Iju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6BfhFfBn5zi"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/RECsys/RECsys_Datafiles/Industrial_and_Scientific_5.json.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création de la fonction pour lire et décompresser le fichier de données\n"
      ],
      "metadata": {
        "id": "m1GJVjZZ0VjH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzIqNiNHn5zj"
      },
      "outputs": [],
      "source": [
        "def readJSON(file_path, inChunks, percentage):\n",
        "    \"\"\"\n",
        "    The readJSON function decompresses a .gz file containing list of Json\n",
        "    onjects and reads in chunks when the inChunks parameter is set to True.\n",
        "\n",
        "    :file_path: The path of the file to be read.\n",
        "    :inChunks:  If True, reads the file in chunks based on the percentage\n",
        "    parameter.\n",
        "                If False, reads the entire file.\n",
        "    :percentage: The total percentage to read from the file if inChunks is True.\n",
        "    :return: returns a list of Json objects.\n",
        "    \"\"\"\n",
        "\n",
        "    json_objects = []\n",
        "\n",
        "    if (inChunks is False):\n",
        "        precentage = 1\n",
        "\n",
        "    with gzip.open(file_path, 'rt') as f:\n",
        "        total_lines = sum(1 for line in f)\n",
        "        fraction = round(total_lines * percentage)\n",
        "\n",
        "    with gzip.open(file_path, 'rt') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i > fraction:\n",
        "              break\n",
        "            try:\n",
        "              json_data = json.loads(line)\n",
        "              json_objects.append(json_data)\n",
        "            except json.JSONDecodeError:\n",
        "              print(f\"Error parsing line: {line}\")\n",
        "\n",
        "    return json_objects"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lecture des fichiers : nous n'avons pas utilisé le mode \"inChunks\" car nous n'avons pas utilisé de grands ensembles de données, mais la fonction sera utile pour les cas d'utilisation futurs."
      ],
      "metadata": {
        "id": "ZKZL8C0y0cTQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LdOjFDon5zk"
      },
      "outputs": [],
      "source": [
        "read_json = readJSON(file_path, inChunks=False, percentage=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversion du tableau d'objets JSON en un dataframe pandas.\n",
        "\n",
        "Le choix de convertir d'abord en un dataframe pandas était nécessaire car le dataframe Spark avait des problèmes pour lire les données car certaines valeurs contenaient des virgules."
      ],
      "metadata": {
        "id": "owKlGoMa0uOI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwqqtHA5n5zl"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame.from_records(read_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, nous supprimons l'ancien tableau JSON, juste pour libérer plus d'espace mémoire. Cela n'aura pas beaucoup d'importance compte tenu de la taille de l'ensemble de données actuellement utilisé."
      ],
      "metadata": {
        "id": "Kn7UNACm04Hn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au0zChxRn5zl"
      },
      "outputs": [],
      "source": [
        "del read_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rm_Pm9Tn5zl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "35564fe1-42c1-4c1d-f855-167934ee7fef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   overall  verified   reviewTime      reviewerID        asin  \\\n",
              "0      5.0      True  11 27, 2017  A1JB7HFWHRYHT7  B0000223SI   \n",
              "1      5.0      True   11 4, 2017  A2FCLJG5GV8SD6  B0000223SI   \n",
              "2      5.0     False  10 27, 2017  A3IT9B33NWYQSL  B0000223SI   \n",
              "3      4.0      True  01 13, 2018   AUL5LCV4TT73P  B0000223SK   \n",
              "4      5.0      True   10 7, 2017  A1V3I3L5JKO7TM  B0000223SK   \n",
              "\n",
              "                    style    reviewerName  \\\n",
              "0  {'Size:': ' 1-(Pack)'}         Alex W.   \n",
              "1  {'Size:': ' 1-(Pack)'}  Randall Harris   \n",
              "2  {'Size:': ' 1-(Pack)'}           A. C.   \n",
              "3    {'Size:': ' 1-Pack'}             TnT   \n",
              "4    {'Size:': ' 1-Pack'}      John Jones   \n",
              "\n",
              "                                          reviewText  \\\n",
              "0  This worked really well for what I used it for...   \n",
              "1                   Fast cutting and good adheasive.   \n",
              "2  Worked great for my lapping bench.  I would li...   \n",
              "3                                      As advertised   \n",
              "4  seems like a pretty good value as opposed to b...   \n",
              "\n",
              "                                             summary  unixReviewTime vote  \\\n",
              "0   Couldn't have been happier with it's performance      1511740800  NaN   \n",
              "1                                        Good paper.      1509753600  NaN   \n",
              "2                                             Handy!      1509062400  NaN   \n",
              "3                                      As advertised      1515801600  NaN   \n",
              "4  seems like a pretty good value as opposed to b...      1507334400  NaN   \n",
              "\n",
              "  image  \n",
              "0   NaN  \n",
              "1   NaN  \n",
              "2   NaN  \n",
              "3   NaN  \n",
              "4   NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-488ceec6-cc87-45fb-aa24-ad97c7c0384e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>style</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>vote</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 27, 2017</td>\n",
              "      <td>A1JB7HFWHRYHT7</td>\n",
              "      <td>B0000223SI</td>\n",
              "      <td>{'Size:': ' 1-(Pack)'}</td>\n",
              "      <td>Alex W.</td>\n",
              "      <td>This worked really well for what I used it for...</td>\n",
              "      <td>Couldn't have been happier with it's performance</td>\n",
              "      <td>1511740800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>11 4, 2017</td>\n",
              "      <td>A2FCLJG5GV8SD6</td>\n",
              "      <td>B0000223SI</td>\n",
              "      <td>{'Size:': ' 1-(Pack)'}</td>\n",
              "      <td>Randall Harris</td>\n",
              "      <td>Fast cutting and good adheasive.</td>\n",
              "      <td>Good paper.</td>\n",
              "      <td>1509753600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>False</td>\n",
              "      <td>10 27, 2017</td>\n",
              "      <td>A3IT9B33NWYQSL</td>\n",
              "      <td>B0000223SI</td>\n",
              "      <td>{'Size:': ' 1-(Pack)'}</td>\n",
              "      <td>A. C.</td>\n",
              "      <td>Worked great for my lapping bench.  I would li...</td>\n",
              "      <td>Handy!</td>\n",
              "      <td>1509062400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>True</td>\n",
              "      <td>01 13, 2018</td>\n",
              "      <td>AUL5LCV4TT73P</td>\n",
              "      <td>B0000223SK</td>\n",
              "      <td>{'Size:': ' 1-Pack'}</td>\n",
              "      <td>TnT</td>\n",
              "      <td>As advertised</td>\n",
              "      <td>As advertised</td>\n",
              "      <td>1515801600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>10 7, 2017</td>\n",
              "      <td>A1V3I3L5JKO7TM</td>\n",
              "      <td>B0000223SK</td>\n",
              "      <td>{'Size:': ' 1-Pack'}</td>\n",
              "      <td>John Jones</td>\n",
              "      <td>seems like a pretty good value as opposed to b...</td>\n",
              "      <td>seems like a pretty good value as opposed to b...</td>\n",
              "      <td>1507334400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-488ceec6-cc87-45fb-aa24-ad97c7c0384e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-488ceec6-cc87-45fb-aa24-ad97c7c0384e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-488ceec6-cc87-45fb-aa24-ad97c7c0384e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea16f9db-8bce-4e81-8a33-6d19cd675d1a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea16f9db-8bce-4e81-8a33-6d19cd675d1a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea16f9db-8bce-4e81-8a33-6d19cd675d1a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 77071,\n  \"fields\": [\n    {\n      \"column\": \"overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9496684020893753,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.0,\n          2.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"verified\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewTime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2930,\n        \"samples\": [\n          \"07 9, 2016\",\n          \"04 19, 2018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewerID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11041,\n        \"samples\": [\n          \"A1566LCK7NPGX8\",\n          \"AFAFD8L0SENRB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5334,\n        \"samples\": [\n          \"B00171JEC6\",\n          \"B00YMM6IQW\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"style\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewerName\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9785,\n        \"samples\": [\n          \"BeccaM\",\n          \"A. Rabun\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 58330,\n        \"samples\": [\n          \"I had some extra money and i always wanted to buy a 3d printer for my personal use and to keep at work for the occasional prototype.  I have an engineering/machining background.  I also have experience in 3D printing due to a course i had in college.  Our machines were much higher-end machines (Stratasys and OBJET) so i knew about file formats and slicing. This is my first experience however with a consumer grade machine and i am deeply enjoying a challenge.\\n\\nThe Problems:\\nWhen i first received the package, i took an inventory and i found nothing was missing.  I did find one of the support legs of the main frame had a chip out of the plexiglass.  Quick email to support@reprapguru.com and the part is on its way.  These things happen and i am more than satisfied with how it was handled.\\n\\nAnother problem i had was when i plugged in the Ramps 1.4 board, the Arduino would shut off and would send an alert to my computer that it was drawing too much power.  I double checked that my limit switches were oriented correctly (Manual makes this perfectly clear you can destroy a voltage regulator on the Arduino Mega if you have them backward.)  I located the problem on one of the switches itself.  The switch had a solder bridge on it so it was shorting two pins together.  Thankfully my board wasn't destroyed.\\n\\nFinally, i wish the printer came with tech-flex so that we can tame the medusa of wires after all the connections are made.\\n\\nThe good:\\nThis machine is infinitely adaptable and if you understand the process... quite capable of excellent print quality.  I bought it hoping it wouldn't require too much tweaking (i don't like unnecessary tweaking) but understand it is a necessary evil sometimes.  This machine has brought it to a manageable level.  If you have no desire to troubleshoot or find it hard to think critically to why a problem has arisen, maybe try another machine.  If you follow the directions though, you will be very close to what you need to get up and running.  I am very glad i purchased this machine vs. a davinci jr.\\n\\nSetup:\\nIt took me about 8 hours total from unboxing to printing.  Again i am an engineer who understands how limit switches, controllers, and stepper motors interface.  The instructions are thorough enough for a beginner, just don't be in a rush or get frustrated if you have a couple quirks to work out.  I will be buying another if i find i need more machine capacity.\\n\\nUpdate: 5/13/16\\nThis review was done of my own free will to help others make decisions on going with this seller and printer.  I did receive a roll of Black PLA after it was written from the company.\",\n          \"The spool I received was an average thickness of 1.75, a tad over and a tad under in places. Printed well at a range of temperatures but I personally used it between 200-208. Prints looked nice. The filament did cross itself several times while being unspooled which sometimes needed manual intervention. I recommend unrolling a decent section of it before any print you won't be monitoring for a while just to be safe. Will buy again.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39564,\n        \"samples\": [\n          \"Great...\",\n          \"Very economical and good quality\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unixReviewTime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45594069,\n        \"min\": 1051401600,\n        \"max\": 1538092800,\n        \"num_unique_values\": 2930,\n        \"samples\": [\n          1468022400,\n          1524096000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vote\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 184,\n        \"samples\": [\n          \"42\",\n          \"106\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppression des colonnes inutiles"
      ],
      "metadata": {
        "id": "Wwn4d3Eh1GhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2P5SbaGn5zn"
      },
      "outputs": [],
      "source": [
        "df1.drop(columns=['verified', 'reviewTime', 'style', 'reviewerName', 'reviewText',\n",
        "\t\t\t\t  'summary', 'unixReviewTime', 'vote', 'image'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WCbGWXOn5zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f9c7bc-6cc7-4797-934e-85c3a639f9fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "overall       float64\n",
              "reviewerID     object\n",
              "asin           object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "df1.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous définissons ici le schéma pour le dataframe de Spark, puis nous en créons un."
      ],
      "metadata": {
        "id": "lNtcWtnG1mqd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asz2VkdPn5zp"
      },
      "outputs": [],
      "source": [
        "schema = StructType([\n",
        "    StructField(\"overall\", DoubleType(), True),\n",
        "    StructField(\"reviewerID\", StringType(), True),\n",
        "    StructField(\"asin\", StringType(), True)\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame(df1, schema=schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voici une partie des données"
      ],
      "metadata": {
        "id": "fID3rF6H1wx_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEonPq5Tn5zq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1387d77d-7cad-4ceb-f103-e1f9ed96496e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------+----------+\n",
            "|overall|    reviewerID|      asin|\n",
            "+-------+--------------+----------+\n",
            "|    5.0|A1JB7HFWHRYHT7|B0000223SI|\n",
            "|    5.0|A2FCLJG5GV8SD6|B0000223SI|\n",
            "|    5.0|A3IT9B33NWYQSL|B0000223SI|\n",
            "|    4.0| AUL5LCV4TT73P|B0000223SK|\n",
            "|    5.0|A1V3I3L5JKO7TM|B0000223SK|\n",
            "|    5.0|A20X7NCNZ7T5ZK|B0000223SK|\n",
            "|    5.0|A3OBWQ8DTRLW2Q|B0000223SI|\n",
            "|    5.0|A398INYG0ZBUZB|B0000223SK|\n",
            "|    5.0| AEBM08OO8Y9BJ|B0000223SK|\n",
            "|    4.0|A358U1JEA514P6|B0000223SI|\n",
            "|    5.0|A1Z584ZH824BU1|B0000223SI|\n",
            "|    5.0|A3OBWQ8DTRLW2Q|B0000223SK|\n",
            "|    5.0|A2B40VHCBDLC43|B0000223SK|\n",
            "|    5.0|A34O4UAC27ECL6|B0000223SI|\n",
            "|    5.0| ACDP5UBE4ZW3T|B0000223SI|\n",
            "|    3.0|A11MN6521EQ9QD|B0000223SK|\n",
            "|    4.0|A358U1JEA514P6|B0000223SK|\n",
            "|    4.0| AAEPD6U1H2X37|B0000223SK|\n",
            "|    5.0|A1ICJY2HU1QLS1|B0000223SK|\n",
            "|    4.0|A1XUBWNW0UFITU|B0000223SK|\n",
            "+-------+--------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons essayer d'imprimer le schéma ici"
      ],
      "metadata": {
        "id": "LezasgLF11CZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUuVqjmUn5zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28bbd81d-b4f8-4b17-d8ba-d72d70392aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- overall: double (nullable = true)\n",
            " |-- reviewerID: string (nullable = true)\n",
            " |-- asin: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le bloc de code suivant a été utilisé pour renommer les noms de colonnes par d'autres plus utiles"
      ],
      "metadata": {
        "id": "zu5vcXyP15a7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "-czMYPdsn5zr"
      },
      "outputs": [],
      "source": [
        "data = data.withColumnRenamed(\"overall\", \"rating\").withColumnRenamed(\"reviewerID\", \"userID\").withColumnRenamed(\"asin\", \"productID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "kC-HrXE-n5zs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38c7015-1b12-4896-99df-fb23bca86bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------+----------+\n",
            "|rating|        userID| productID|\n",
            "+------+--------------+----------+\n",
            "|   5.0|A1JB7HFWHRYHT7|B0000223SI|\n",
            "|   5.0|A2FCLJG5GV8SD6|B0000223SI|\n",
            "|   5.0|A3IT9B33NWYQSL|B0000223SI|\n",
            "|   4.0| AUL5LCV4TT73P|B0000223SK|\n",
            "|   5.0|A1V3I3L5JKO7TM|B0000223SK|\n",
            "|   5.0|A20X7NCNZ7T5ZK|B0000223SK|\n",
            "|   5.0|A3OBWQ8DTRLW2Q|B0000223SI|\n",
            "|   5.0|A398INYG0ZBUZB|B0000223SK|\n",
            "|   5.0| AEBM08OO8Y9BJ|B0000223SK|\n",
            "|   4.0|A358U1JEA514P6|B0000223SI|\n",
            "|   5.0|A1Z584ZH824BU1|B0000223SI|\n",
            "|   5.0|A3OBWQ8DTRLW2Q|B0000223SK|\n",
            "|   5.0|A2B40VHCBDLC43|B0000223SK|\n",
            "|   5.0|A34O4UAC27ECL6|B0000223SI|\n",
            "|   5.0| ACDP5UBE4ZW3T|B0000223SI|\n",
            "|   3.0|A11MN6521EQ9QD|B0000223SK|\n",
            "|   4.0|A358U1JEA514P6|B0000223SK|\n",
            "|   4.0| AAEPD6U1H2X37|B0000223SK|\n",
            "|   5.0|A1ICJY2HU1QLS1|B0000223SK|\n",
            "|   4.0|A1XUBWNW0UFITU|B0000223SK|\n",
            "+------+--------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les deux cellules suivantes sont très nécessaires, car les modèles ALS n'acceptent pas les ID d'utilisateurs et d'articles non numériques, nous convertissons donc les ID en d'autres numériques."
      ],
      "metadata": {
        "id": "8JBYi-ZJ2G4A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "3PuTPbnUn5zs"
      },
      "outputs": [],
      "source": [
        "indexer = StringIndexer(inputCol=\"userID\", outputCol=\"userIDIndex\")\n",
        "data = indexer.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "2G9AOg6Tn5zt"
      },
      "outputs": [],
      "source": [
        "indexer = StringIndexer(inputCol=\"productID\", outputCol=\"productIDIndex\")\n",
        "data = indexer.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "NZrW5XfJn5zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c30daa-3adf-4e00-febe-0275fd8ed71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------+----------+-----------+--------------+\n",
            "|rating|        userID| productID|userIDIndex|productIDIndex|\n",
            "+------+--------------+----------+-----------+--------------+\n",
            "|   5.0|A1JB7HFWHRYHT7|B0000223SI|     1078.0|        1465.0|\n",
            "|   5.0|A2FCLJG5GV8SD6|B0000223SI|     8222.0|        1465.0|\n",
            "|   5.0|A3IT9B33NWYQSL|B0000223SI|     5689.0|        1465.0|\n",
            "|   4.0| AUL5LCV4TT73P|B0000223SK|     1371.0|         720.0|\n",
            "|   5.0|A1V3I3L5JKO7TM|B0000223SK|     7535.0|         720.0|\n",
            "|   5.0|A20X7NCNZ7T5ZK|B0000223SK|     7742.0|         720.0|\n",
            "|   5.0|A3OBWQ8DTRLW2Q|B0000223SI|     5800.0|        1465.0|\n",
            "|   5.0|A398INYG0ZBUZB|B0000223SK|      153.0|         720.0|\n",
            "|   5.0| AEBM08OO8Y9BJ|B0000223SK|     1814.0|         720.0|\n",
            "|   4.0|A358U1JEA514P6|B0000223SI|     3527.0|        1465.0|\n",
            "|   5.0|A1Z584ZH824BU1|B0000223SI|     7669.0|        1465.0|\n",
            "|   5.0|A3OBWQ8DTRLW2Q|B0000223SK|     5800.0|         720.0|\n",
            "|   5.0|A2B40VHCBDLC43|B0000223SK|     4949.0|         720.0|\n",
            "|   5.0|A34O4UAC27ECL6|B0000223SI|     3515.0|        1465.0|\n",
            "|   5.0| ACDP5UBE4ZW3T|B0000223SI|    10232.0|        1465.0|\n",
            "|   3.0|A11MN6521EQ9QD|B0000223SK|     6548.0|         720.0|\n",
            "|   4.0|A358U1JEA514P6|B0000223SK|     3527.0|         720.0|\n",
            "|   4.0| AAEPD6U1H2X37|B0000223SK|     3879.0|         720.0|\n",
            "|   5.0|A1ICJY2HU1QLS1|B0000223SK|     7113.0|         720.0|\n",
            "|   4.0|A1XUBWNW0UFITU|B0000223SK|     1526.0|         720.0|\n",
            "+------+--------------+----------+-----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimons une ligne spécifique"
      ],
      "metadata": {
        "id": "tXAOGaXw2WJL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "Bho3ZpqPn5zt"
      },
      "outputs": [],
      "source": [
        "specific_line = data.limit(1).collect()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "SyHsrZlQn5zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ed71a8-0cff-4fba-9332-7c512f45a5d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(rating=5.0, userID='A1JB7HFWHRYHT7', productID='B0000223SI', userIDIndex=1078.0, productIDIndex=1465.0)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "specific_line"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le nombre total de lignes disponibles"
      ],
      "metadata": {
        "id": "6Th5VSVw2X9L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "6-B_yr3qn5zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0699d9c2-b683-4c44-8efc-0a2db8a80ab4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77071"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "num_rows = data.count()\n",
        "num_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuite, nous allons supprimer les valeurs nulles et les doublons"
      ],
      "metadata": {
        "id": "FsDqMhK22adV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "LAa9YEDXn5zu"
      },
      "outputs": [],
      "source": [
        "data = data.dropna().drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le nombre de points de données restants"
      ],
      "metadata": {
        "id": "YgTkErwB2ho0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "ajc2g5X_n5zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bda42c2-501c-4f86-a3e4-a6d043e70c5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72131"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "num_rows = data.count()\n",
        "num_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons maintenant diviser l'ensemble de données en une répartition train/test"
      ],
      "metadata": {
        "id": "PbCSimGG2lcg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "qZIy4eCon5zv"
      },
      "outputs": [],
      "source": [
        "(train, test) = data.randomSplit([0.7, 0.3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La cellule suivante contient le code nécessaire pour l'appel initial d'ALS"
      ],
      "metadata": {
        "id": "5Ohin6XS2qyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "Jrwjh51On5zw"
      },
      "outputs": [],
      "source": [
        "als = ALS(maxIter=11, regParam=0.01, userCol=\"userIDIndex\", itemCol=\"productIDIndex\", ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajustement du modèle sur l'ensemble de données du train\n"
      ],
      "metadata": {
        "id": "u4izaOo04Xxb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "LpNKTE6Jn5zw"
      },
      "outputs": [],
      "source": [
        "model = als.fit(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faire des prédictions pour le test Dataset"
      ],
      "metadata": {
        "id": "PhELSgkd4lEH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "NI9Bnv-Zn5zw"
      },
      "outputs": [],
      "source": [
        "predictions = model.transform(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation des prédictions initials"
      ],
      "metadata": {
        "id": "b7YI5SkO4nwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq1TQpOy4PdH",
        "outputId": "3183ecce-6636-440f-e9fb-0d7f8fc76cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 4.751013689962461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliser Gridsearch pour voir les meilleurs paramètres pour notre ALS model"
      ],
      "metadata": {
        "id": "JUueVZPB5NqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définir la grille des paramètres pour la recherche\n",
        "param_grid = {\n",
        "    \"maxIter\": [7, 12, 17],  # Nombre maximum d'itérations\n",
        "    \"regParam\": [0.01, 0.05, 0.1],  # Paramètre de régularisation\n",
        "    \"rank\": [5, 10, 15]  # Rang des facteurs latents\n",
        "}\n",
        "\n",
        "# Définir les métriques d'évaluation\n",
        "metrics = ['rmse', 'mae', 'r2']\n",
        "evaluators = {metric: RegressionEvaluator(metricName=metric, labelCol=\"rating\", predictionCol=\"prediction\") for metric in metrics}\n",
        "\n",
        "# Initialiser les meilleurs modèles et scores pour chaque métrique\n",
        "best_models = {metric: None for metric in metrics}\n",
        "best_scores = {metric: float(\"inf\") if metric != 'r2' else float(\"-inf\") for metric in metrics}\n",
        "\n",
        "# Tester chaque combinaison de paramètres\n",
        "for params in itertools.product(*param_grid.values()):\n",
        "    param_dict = dict(zip(param_grid.keys(), params))  # Créer un dictionnaire de paramètres\n",
        "    als = ALS(maxIter=param_dict[\"maxIter\"], regParam=param_dict[\"regParam\"], rank=param_dict[\"rank\"],\n",
        "              userCol=\"userIDIndex\", itemCol=\"productIDIndex\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "\n",
        "    model = als.fit(train)  # Entraîner le modèle sur les données d'entraînement\n",
        "    predictions = model.transform(test)  # Faire des prédictions sur les données de test\n",
        "\n",
        "    # Évaluer le modèle pour chaque métrique\n",
        "    for metric, evaluator in evaluators.items():\n",
        "        score = evaluator.evaluate(predictions)\n",
        "        # Mettre à jour les meilleurs scores et modèles si nécessaire\n",
        "        if (metric != 'r2' and score < best_scores[metric]) or (metric == 'r2' and score > best_scores[metric]):\n",
        "            best_scores[metric] = score\n",
        "            best_models[metric] = model\n",
        "\n",
        "# Afficher les meilleurs paramètres et scores pour chaque métrique\n",
        "for metric in metrics:\n",
        "    print(f\"Meilleurs paramètres pour {metric}: {best_models[metric]._java_obj.parent().extractParamMap()}\")\n",
        "    print(f\"Meilleur {metric}: {best_scores[metric]}\")\n"
      ],
      "metadata": {
        "id": "JvhEMom5SwOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sauvegarder le model pour le déploiment"
      ],
      "metadata": {
        "id": "AkkQXbOg5iqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models['rmse'].save(\"/content/drive/MyDrive/RECsys/RECsys_Datafiles/als_model\")"
      ],
      "metadata": {
        "id": "NkMk8ocMu1_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}